{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tvAKGat01Sd"
   },
   "source": [
    "# **Penting**\n",
    "- Pastikan Anda melakukan Run All sebelum mengirimkan submission untuk memastikan seluruh cell berjalan dengan baik.\n",
    "- Hapus simbol pagar (#) jika Anda menerapkan kriteria tambahan\n",
    "- Biarkan simbol pagar (#) jika Anda tidak menerapkan kriteria tambahan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKADPWcFKlj3"
   },
   "source": [
    "# **1. Import Library**\n",
    "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "BlmvjLY9M4Yj"
   },
   "outputs": [],
   "source": [
    "#Type your code here\n",
    "# Import library yang dibutuhkan\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3YIEnAFKrKL"
   },
   "source": [
    "# **2. Memuat Dataset dari Hasil Clustering**\n",
    "Memuat dataset hasil clustering dari file CSV ke dalam variabel DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "GHCGNTyrM5fS"
   },
   "outputs": [],
   "source": [
    "# Gunakan dataset hasil clustering yang memiliki fitur Target\n",
    "# Silakan gunakan dataset data_clustering jika tidak menerapkan Interpretasi Hasil Clustering [Advanced]\n",
    "# Silakan gunakan dataset data_clustering_inverse jika menerapkan Interpretasi Hasil Clustering [Advanced]\n",
    "# Gunakan dataset hasil clustering\n",
    "df_cluster = pd.read_csv('data_clustering_inverse.csv')  # atau 'data_clustering.csv' jika tidak pakai inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "bCsep0NZ0LUf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>AccountID</th>\n",
       "      <th>TransactionAmount</th>\n",
       "      <th>TransactionDate</th>\n",
       "      <th>TransactionType</th>\n",
       "      <th>Location</th>\n",
       "      <th>DeviceID</th>\n",
       "      <th>IP Address</th>\n",
       "      <th>MerchantID</th>\n",
       "      <th>Channel</th>\n",
       "      <th>CustomerAge</th>\n",
       "      <th>CustomerOccupation</th>\n",
       "      <th>TransactionDuration</th>\n",
       "      <th>LoginAttempts</th>\n",
       "      <th>AccountBalance</th>\n",
       "      <th>PreviousTransactionDate</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TX000001</td>\n",
       "      <td>AC00128</td>\n",
       "      <td>14.09</td>\n",
       "      <td>2023-04-11 16:29:14</td>\n",
       "      <td>Debit</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>D000380</td>\n",
       "      <td>162.198.218.92</td>\n",
       "      <td>M015</td>\n",
       "      <td>ATM</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5112.21</td>\n",
       "      <td>2024-11-04 08:08:08</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TX000002</td>\n",
       "      <td>AC00455</td>\n",
       "      <td>376.24</td>\n",
       "      <td>2023-06-27 16:44:19</td>\n",
       "      <td>Debit</td>\n",
       "      <td>Houston</td>\n",
       "      <td>D000051</td>\n",
       "      <td>13.149.61.4</td>\n",
       "      <td>M052</td>\n",
       "      <td>ATM</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>141.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13758.91</td>\n",
       "      <td>2024-11-04 08:09:35</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TX000003</td>\n",
       "      <td>AC00019</td>\n",
       "      <td>126.29</td>\n",
       "      <td>2023-07-10 18:16:08</td>\n",
       "      <td>Debit</td>\n",
       "      <td>Mesa</td>\n",
       "      <td>D000235</td>\n",
       "      <td>215.97.143.157</td>\n",
       "      <td>M009</td>\n",
       "      <td>Online</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Student</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1122.35</td>\n",
       "      <td>2024-11-04 08:07:04</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TX000004</td>\n",
       "      <td>AC00070</td>\n",
       "      <td>184.50</td>\n",
       "      <td>2023-05-05 16:32:11</td>\n",
       "      <td>Debit</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>D000187</td>\n",
       "      <td>200.13.225.150</td>\n",
       "      <td>M002</td>\n",
       "      <td>Online</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Student</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8569.06</td>\n",
       "      <td>2024-11-04 08:09:06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TX000005</td>\n",
       "      <td>AC00411</td>\n",
       "      <td>13.45</td>\n",
       "      <td>2023-10-16 17:51:24</td>\n",
       "      <td>Credit</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>D000308</td>\n",
       "      <td>65.164.3.100</td>\n",
       "      <td>M091</td>\n",
       "      <td>Online</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Student</td>\n",
       "      <td>198.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7429.40</td>\n",
       "      <td>2024-11-04 08:06:39</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TransactionID AccountID  TransactionAmount      TransactionDate  \\\n",
       "0      TX000001   AC00128              14.09  2023-04-11 16:29:14   \n",
       "1      TX000002   AC00455             376.24  2023-06-27 16:44:19   \n",
       "2      TX000003   AC00019             126.29  2023-07-10 18:16:08   \n",
       "3      TX000004   AC00070             184.50  2023-05-05 16:32:11   \n",
       "4      TX000005   AC00411              13.45  2023-10-16 17:51:24   \n",
       "\n",
       "  TransactionType   Location DeviceID      IP Address MerchantID Channel  \\\n",
       "0           Debit  San Diego  D000380  162.198.218.92       M015     ATM   \n",
       "1           Debit    Houston  D000051     13.149.61.4       M052     ATM   \n",
       "2           Debit       Mesa  D000235  215.97.143.157       M009  Online   \n",
       "3           Debit    Raleigh  D000187  200.13.225.150       M002  Online   \n",
       "4          Credit    Atlanta  D000308    65.164.3.100       M091  Online   \n",
       "\n",
       "   CustomerAge CustomerOccupation  TransactionDuration  LoginAttempts  \\\n",
       "0         70.0             Doctor                 81.0            1.0   \n",
       "1         68.0             Doctor                141.0            1.0   \n",
       "2         19.0            Student                 56.0            1.0   \n",
       "3         26.0            Student                 25.0            1.0   \n",
       "4          NaN            Student                198.0            1.0   \n",
       "\n",
       "   AccountBalance PreviousTransactionDate  Target  \n",
       "0         5112.21     2024-11-04 08:08:08     3.0  \n",
       "1        13758.91     2024-11-04 08:09:35     2.0  \n",
       "2         1122.35     2024-11-04 08:07:04     1.0  \n",
       "3         8569.06     2024-11-04 08:09:06     0.0  \n",
       "4         7429.40     2024-11-04 08:06:39     1.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tampilkan 5 baris pertama dengan function head.\n",
    "# Tampilkan 5 baris pertama\n",
    "df_cluster.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KkPem5eWL2UP"
   },
   "source": [
    "# **3. Data Splitting**\n",
    "Tahap Data Splitting bertujuan untuk memisahkan dataset menjadi dua bagian: data latih (training set) dan data uji (test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "OubAW-7ONKVj"
   },
   "outputs": [],
   "source": [
    "# Menggunakan train_test_split() untuk melakukan pembagian dataset.\n",
    "# Pisahkan fitur (X) dan label (y)\n",
    "X = df_cluster.drop('Target', axis=1)\n",
    "y = df_cluster['Target']\n",
    "\n",
    "# Bagi menjadi data latih dan uji\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVPbB03CMhTT"
   },
   "source": [
    "# **4. Membangun Model Klasifikasi**\n",
    "Setelah memilih algoritma klasifikasi yang sesuai, langkah selanjutnya adalah melatih model menggunakan data latih.\n",
    "\n",
    "Berikut adalah rekomendasi tahapannya.\n",
    "1. Menggunakan algoritma klasifikasi yaitu Decision Tree.\n",
    "2. Latih model menggunakan data yang sudah dipisah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print('Target' in df_cluster.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TransactionID', 'AccountID', 'TransactionAmount', 'TransactionDate', 'TransactionType', 'Location', 'DeviceID', 'IP Address', 'MerchantID', 'Channel', 'CustomerAge', 'CustomerOccupation', 'TransactionDuration', 'LoginAttempts', 'AccountBalance', 'PreviousTransactionDate', 'Target']\n"
     ]
    }
   ],
   "source": [
    "print(df_cluster.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop kolom ID dan tanggal karena tidak relevan untuk prediksi Target\n",
    "cols_to_drop = ['TransactionID', 'AccountID', 'TransactionDate', 'PreviousTransactionDate',\n",
    "               'DeviceID', 'IP Address', 'MerchantID']\n",
    "\n",
    "df_cluster = df_cluster.drop(columns=cols_to_drop, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransactionAmount      26\n",
      "TransactionType        30\n",
      "Location               30\n",
      "Channel                27\n",
      "CustomerAge            18\n",
      "CustomerOccupation     23\n",
      "TransactionDuration    26\n",
      "LoginAttempts          21\n",
      "AccountBalance         27\n",
      "Target                 70\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cek missing values\n",
    "print(df_cluster.isnull().sum())\n",
    "\n",
    "# Imputasi nilai kosong jika ada\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent')  # atau 'mean' untuk numerik\n",
    "df_clean = df_cluster.copy()\n",
    "df_clean[df_clean.select_dtypes(include=['object']).columns] = imputer.fit_transform(\n",
    "    df_clean.select_dtypes(include=['object'])\n",
    ")\n",
    "df_clean[df_clean.select_dtypes(include=['number']).columns] = imputer.fit_transform(\n",
    "    df_clean.select_dtypes(include=['number'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode fitur kategorikal dengan pd.get_dummies\n",
    "categorical_cols = df_clean.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Pastikan Target tidak ikut di-encode\n",
    "if 'Target' in categorical_cols:\n",
    "    categorical_cols.remove('Target')\n",
    "\n",
    "# One-hot encoding\n",
    "df_encoded = pd.get_dummies(df_clean, columns=categorical_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pisahkan fitur dan label\n",
    "X = df_encoded.drop('Target', axis=1)\n",
    "y = df_encoded['Target']\n",
    "\n",
    "# Split data menjadi train dan test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.33858267716535434\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.23      0.23      0.23       114\n",
      "         1.0       0.48      0.49      0.48       220\n",
      "         2.0       0.15      0.14      0.15        50\n",
      "         3.0       0.25      0.26      0.25       124\n",
      "\n",
      "    accuracy                           0.34       508\n",
      "   macro avg       0.28      0.28      0.28       508\n",
      "weighted avg       0.34      0.34      0.34       508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Buat model\n",
    "model_dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Latih model\n",
    "model_dt.fit(X_train, y_train)\n",
    "\n",
    "# Prediksi\n",
    "y_pred = model_dt.predict(X_test)\n",
    "\n",
    "# Evaluasi\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['decision_tree_model.h5']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Simpan model\n",
    "joblib.dump(model_dt, 'decision_tree_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.39173228346456695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.17      0.06      0.09       114\n",
      "         1.0       0.43      0.81      0.56       220\n",
      "         2.0       0.00      0.00      0.00        50\n",
      "         3.0       0.28      0.10      0.15       124\n",
      "\n",
      "    accuracy                           0.39       508\n",
      "   macro avg       0.22      0.24      0.20       508\n",
      "weighted avg       0.29      0.39      0.30       508\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['explore_RandomForest_classification.h5']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Latih model lain\n",
    "model_rf = RandomForestClassifier(random_state=42)\n",
    "model_rf.fit(X_train, y_train)\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "# Evaluasi\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Simpan model\n",
    "joblib.dump(model_rf, 'explore_RandomForest_classification.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "Tuned Model Accuracy: 0.43700787401574803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.03      0.05       114\n",
      "         1.0       0.43      0.98      0.60       220\n",
      "         2.0       1.00      0.02      0.04        50\n",
      "         3.0       0.67      0.02      0.03       124\n",
      "\n",
      "    accuracy                           0.44       508\n",
      "   macro avg       0.63      0.26      0.18       508\n",
      "weighted avg       0.55      0.44      0.28       508\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tuning_classification.h5']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 4, 6],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Tuned Model Accuracy:\", accuracy_score(y_test, y_pred_best))\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "\n",
    "# Simpan model hasil tuning\n",
    "joblib.dump(best_model, 'tuning_classification.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "4JYxBe87NLDk"
   },
   "outputs": [],
   "source": [
    "# Buatlah model klasifikasi menggunakan Decision Tree\n",
    "# Buat model klasifikasi menggunakan Decision Tree\n",
    "model_dt = DecisionTreeClassifier(random_state=42)\n",
    "model_dt.fit(X_train, y_train)\n",
    "\n",
    "# Prediksi\n",
    "y_pred_dt = model_dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "P_AakAxghYv-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['decision_tree_model.h5']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menyimpan Model\n",
    "# import joblib\n",
    "# joblib.dump(model, 'decision_tree_model.h5')\n",
    "# Simpan model Decision Tree\n",
    "joblib.dump(model_dt, 'decision_tree_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epO4HhrzBXMg"
   },
   "source": [
    "# **5. Memenuhi Kriteria Skilled dan Advanced dalam Membangun Model Klasifikasi**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNOEZk24uiXu"
   },
   "source": [
    "**Biarkan kosong jika tidak menerapkan kriteria skilled atau advanced**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "kB_8LIWMATl6"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Latih model lain: Random Forest\n",
    "model_rf = RandomForestClassifier(random_state=42)\n",
    "model_rf.fit(X_train, y_train)\n",
    "y_pred_rf = model_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "bRlKm5BVAT91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Decision Tree\n",
      "Accuracy: 0.3386, Precision: 0.3368, Recall: 0.3386, F1-Score: 0.3377\n",
      "\n",
      "Model Random Forest\n",
      "Accuracy: 0.3917, Precision: 0.2917, Recall: 0.3917, F1-Score: 0.3008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan hasil evaluasi akurasi, presisi, recall, dan F1-Score pada seluruh algoritma yang sudah dibuat.\n",
    "# Evaluasi kedua model\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average='weighted')\n",
    "    rec = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    print(f\"Model {model_name}\")\n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\\n\")\n",
    "\n",
    "evaluate_model(y_test, y_pred_dt, \"Decision Tree\")\n",
    "evaluate_model(y_test, y_pred_rf, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "dUPItkbXBNkO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['explore_RandomForest_classification.h5']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menyimpan Model Selain Decision Tree\n",
    "# Model ini bisa lebih dari satu\n",
    "# import joblib\n",
    "# joblib.dump(___, 'explore_<Nama Algoritma>_classification.h5')\n",
    "# Simpan model Random Forest\n",
    "joblib.dump(model_rf, 'explore_RandomForest_classification.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u23H2guj-h9h"
   },
   "source": [
    "Hyperparameter Tuning Model\n",
    "\n",
    "Pilih salah satu algoritma yang ingin Anda tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "dFCTxJJq-m-l"
   },
   "outputs": [],
   "source": [
    "# Lakukan Hyperparameter Tuning dan Latih ulang.\n",
    "# Hyperparameter tuning menggunakan GridSearchCV\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 4, 6],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "1g6EPSSWxjcQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Tuned Decision Tree\n",
      "Accuracy: 0.4370, Precision: 0.5455, Recall: 0.4370, F1-Score: 0.2836\n",
      "\n",
      "Best Parameters: {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan hasil evaluasi akurasi, presisi, recall, dan F1-Score pada algoritma yang sudah dituning.\n",
    "# Evaluasi model setelah tuning\n",
    "evaluate_model(y_test, y_pred_best, \"Tuned Decision Tree\")\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "7UJNcVP--n7S"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tuning_classification.h5']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menyimpan Model hasil tuning\n",
    "# import joblib\n",
    "# joblib.dump(model_dt, 'tuning_classification.h5')\n",
    "# Simpan model hasil tuning\n",
    "joblib.dump(best_model, 'tuning_classification.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epO4HhrzBXMg"
   },
   "source": [
    "# **6. Reduksi Dimensi dengan PCA & Clustering (Tambahan Skilled/Advanced)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Preprocessing: Drop kolom tidak relevan dan imputasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['TransactionID', 'AccountID', 'TransactionDate', 'PreviousTransactionDate',\n",
    "                'DeviceID', 'IP Address', 'MerchantID']\n",
    "df = pd.read_csv('data_clustering_inverse.csv')  # atau 'data_clustering.csv'\n",
    "df = df.drop(columns=cols_to_drop, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Imputasi nilai kosong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "df[df.select_dtypes(include='object').columns] = imputer.fit_transform(df.select_dtypes(include='object'))\n",
    "df[df.select_dtypes(include='number').columns] = imputer.fit_transform(df.select_dtypes(include='number'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Encoding kategorikal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Standardisasi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_encoded.drop(columns=['Target'], errors='ignore'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. PCA - Reduksi dimensi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Clustering dengan KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(X_pca)\n",
    "\n",
    "# Tambahkan hasil cluster ke dataframe\n",
    "df['Target'] = cluster_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epO4HhrzBXMg"
   },
   "source": [
    "# **7. Interpretasi Hasil Clustering**\n",
    "Interpretasi cluster dengan menghitung modus untuk fitur kategorikal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       TransactionType    Location Channel CustomerOccupation\n",
      "Target                                                       \n",
      "0                Debit  Fort Worth  Branch            Student\n",
      "1                Debit  Fort Worth     ATM           Engineer\n",
      "2                Debit      Denver  Branch            Retired\n",
      "3                Debit  Fort Worth  Online           Engineer\n"
     ]
    }
   ],
   "source": [
    "# Pilih fitur kategorikal asli\n",
    "categorical_cols = ['TransactionType', 'Location', 'Channel', 'CustomerOccupation']\n",
    "\n",
    "# Hitung modus untuk setiap cluster\n",
    "mode_per_cluster = df.groupby('Target')[categorical_cols].agg(lambda x: x.mode().iloc[0])\n",
    "print(mode_per_cluster)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epO4HhrzBXMg"
   },
   "source": [
    "# **8. Simpan Dataset Hasil Clustering**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_clustering_inverse.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
